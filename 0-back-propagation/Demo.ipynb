{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, ReduceLROnPlateau, LearningRateScheduler, EarlyStopping, TensorBoard\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_x, batch_y = mnist.train.next_batch(batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1047b92b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12804f630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(batch_x[5].reshape((28, 28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "NUM_HIDDEN = 20\n",
    "NUM_OUTPUT = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras - Alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=NUM_HIDDEN, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(units=NUM_OUTPUT, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TB = TensorBoard(log_dir='./logs', histogram_freq=1,\n",
    "                            write_graph=True,  write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 15,910\n",
      "Trainable params: 15,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 5s - loss: 0.4194 - acc: 0.8830 - val_loss: 0.2499 - val_acc: 0.9278\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 4s - loss: 0.2497 - acc: 0.9294 - val_loss: 0.2175 - val_acc: 0.9396\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 5s - loss: 0.2182 - acc: 0.9379 - val_loss: 0.1991 - val_acc: 0.9456\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 5s - loss: 0.1990 - acc: 0.9442 - val_loss: 0.2001 - val_acc: 0.9448\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 4s - loss: 0.1870 - acc: 0.9477 - val_loss: 0.1886 - val_acc: 0.9460\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 5s - loss: 0.1771 - acc: 0.9505 - val_loss: 0.1797 - val_acc: 0.9510\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 5s - loss: 0.1689 - acc: 0.9526 - val_loss: 0.1842 - val_acc: 0.9496\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 5s - loss: 0.1633 - acc: 0.9553 - val_loss: 0.1754 - val_acc: 0.9542\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 5s - loss: 0.1581 - acc: 0.9562 - val_loss: 0.1791 - val_acc: 0.9544\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 5s - loss: 0.1546 - acc: 0.9573 - val_loss: 0.1796 - val_acc: 0.9530\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(mnist.train.images, \n",
    "                    mnist.train.labels,\n",
    "                    epochs=10,\n",
    "                    validation_data=(mnist.validation.images, mnist.validation.labels),\n",
    "                    callbacks=[TB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorBoard b'54' at http://Ramseys-MacBook-Pro.local:6006\n",
      "(Press CTRL+C to quit)\n",
      "WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'K' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d966638f4740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_HIDDEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_OUTPUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'K' is not defined"
     ]
    }
   ],
   "source": [
    "K.backend.clear_session()\n",
    "model = K.models.Sequential()\n",
    "model.add(K.layers.Dense(units=NUM_HIDDEN, activation='relu', input_shape=(784,)))\n",
    "model.add(K.layers.Dense(units=NUM_OUTPUT, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TB = TensorBoard(log_dir='./logs', histogram_freq=1,\n",
    "                            write_graph=True,  write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"dense_1_input:0\", shape=(?, 784), dtype=float32) is not an element of this graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/code/learn/tongda-dl-tutorial/.direnv/python-3.6.1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    941\u001b[0m             subfeed_t = self.graph.as_graph_element(subfeed, allow_tensor=True,\n\u001b[0;32m--> 942\u001b[0;31m                                                     allow_operation=False)\n\u001b[0m\u001b[1;32m    943\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/learn/tongda-dl-tutorial/.direnv/python-3.6.1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2583\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/learn/tongda-dl-tutorial/.direnv/python-3.6.1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2662\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2663\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2664\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"dense_1_input:0\", shape=(?, 784), dtype=float32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a13b7817b0c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(mnist.train.images, mnist.train.labels,\n\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           validation_data=(mnist.validation.images, mnist.validation.labels))\n\u001b[0m",
      "\u001b[0;32m~/code/learn/tongda-dl-tutorial/.direnv/python-3.6.1/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/code/learn/tongda-dl-tutorial/.direnv/python-3.6.1/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/learn/tongda-dl-tutorial/.direnv/python-3.6.1/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/learn/tongda-dl-tutorial/.direnv/python-3.6.1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/learn/tongda-dl-tutorial/.direnv/python-3.6.1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/learn/tongda-dl-tutorial/.direnv/python-3.6.1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    943\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             raise TypeError('Cannot interpret feed_dict key as Tensor: '\n\u001b[0;32m--> 945\u001b[0;31m                             + e.args[0])\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"dense_1_input:0\", shape=(?, 784), dtype=float32) is not an element of this graph."
     ]
    }
   ],
   "source": [
    "model.fit(mnist.train.images, mnist.train.labels,\n",
    "          batch_size=10, epochs=5,\n",
    "          validation_data=(mnist.validation.images, mnist.validation.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Sequential.evaluate of <keras.models.Sequential object at 0x1279d8e10>>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
